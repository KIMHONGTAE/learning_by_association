{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding for the visualizer\n",
    "\n",
    "This notebook shows how to create embeddings for the PCA / tSNE visualizer in tensorboard. We use a trained cifarnet network and feed CIFAR images through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import scipy\n",
    "import cPickle\n",
    "%matplotlib inline\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets as nets\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the data\n",
    "\n",
    "The 32x32 CIFAR images we use here can be obtained from: http://www.cs.toronto.edu/~kriz/cifar.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    data = dict['data']\n",
    "    imgs = np.transpose(np.reshape(data,(-1,32,32,3), order='F'),axes=(0,2,1,3)).astype(np.float) #order batch,x,y,color\n",
    "    y = np.asarray(dict['fine_labels'], dtype='uint8')\n",
    "    return y, imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, imgs = unpickle('/usr/stud/plapp/data/cifar100/test')\n",
    "\n",
    "y.shape, imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the models\n",
    "\n",
    "We use a trained cifarnet network. Use lba to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (?, 32, 32, 3)\n",
      "Number of variables to restore 11\n"
     ]
    }
   ],
   "source": [
    "import semisup\n",
    "\n",
    "from tools.cifar100 import tree\n",
    "from tools.tree import findLabelsFromTree, findLabelsFromTreeMultitask, getWalkerLabel\n",
    "from tools import cifar100 as cifar_tools, dataset_factory, preprocessing_factory, cifar100, data_dirs\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model_path='/usr/stud/plapp/models/multitask_half/model.ckpt-35489'\n",
    "model_path='/usr/stud/plapp/models/lba_multitask_half/model.ckpt-17000'\n",
    "\n",
    "\n",
    "preprocessing_name = \"cifarnet\"#FLAGS.preprocessing_name or FLAGS.model_name\n",
    "image_preprocessing_fn = preprocessing_factory.get_preprocessing(\n",
    "  preprocessing_name,\n",
    "  is_training=False)\n",
    "\n",
    "\n",
    "image = tf.placeholder(tf.float32, [32,32,3])\n",
    "\n",
    "\n",
    "test_images = image_preprocessing_fn(image, 32, 32)\n",
    "\n",
    "\n",
    "model = semisup.SemisupModel(semisup.architectures.cifar_model, tree.num_labels,\n",
    "                             [32,32,3], treeStructure=tree)\n",
    "\n",
    "variables_to_restore = slim.get_variables_to_restore()\n",
    "print('Number of variables to restore {}'.format(len(variables_to_restore)))\n",
    "\n",
    "init_assign_op, init_feed_dict = slim.assign_from_checkpoint(model_path, variables_to_restore)\n",
    "sess = tf.Session()\n",
    "sess.run(init_assign_op, init_feed_dict)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess images\n",
    "for i in range(10000):\n",
    "    imgs[i] = test_images.eval(feed_dict={image: imgs[i]}, session=sess)\n",
    "    #imgs[i] = imgs[i]/128-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 32, 32, 3), (5000, 120), (5000, 192))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "#print g.get_operations()\n",
    "feed = g.get_tensor_by_name('test_in:0')\n",
    "fetch = g.get_tensor_by_name('net/fc4/Relu:0')\n",
    "label = g.get_tensor_by_name('net_1/fully_connected/BiasAdd:0')\n",
    "\n",
    "# Feeding 3 images through the net just for testing\n",
    "feed_vals = imgs[0:5000]\n",
    "\n",
    "res = sess.run([fetch, label], feed_dict={feed:feed_vals})\n",
    "np.shape(feed_vals), res[1].shape, res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('coarse similarity of closest embeddings:', 0.2959)\n",
      "('fine similarity of closest embeddings:', 0.2591)\n"
     ]
    }
   ],
   "source": [
    "#calculate distance matrix\n",
    "s = 5000\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarities = cosine_similarity(res[0])\n",
    "\n",
    "similar_coarse_labels = np.zeros(s)\n",
    "similar_fine_labels = np.zeros(s)\n",
    "labels = (y+99) % 100\n",
    "\n",
    "for j in range(s):        \n",
    "    coarse_label = int(np.math.floor((labels[j]) / 5))\n",
    "    label = [coarse_label, labels[j]]\n",
    "    \n",
    "    # next 10 images\n",
    "    closest_embeddings = (similarities[j][:]).argsort()[-11:-1][::-1]\n",
    "    \n",
    "    labels_for_closest_embeddings = [[int(np.math.floor((labels[i]) / 5)),labels[i]] for i in closest_embeddings]\n",
    "    \n",
    "    same_coarse_label = [l[0] == label[0] for l in labels_for_closest_embeddings]\n",
    "    same_fine_label = [l[1] == label[1] for l in labels_for_closest_embeddings]\n",
    "    \n",
    "    similar_coarse_labels[j] = np.average(same_coarse_label)\n",
    "    similar_fine_labels[j] = np.average(same_fine_label)\n",
    "    \n",
    "    #print(coarse_label, np.average(same_coarse_label), )\n",
    "    #if np.average(same_fine_label) > 0.5:\n",
    "    #    print(j)\n",
    "    \n",
    "print(\"coarse similarity of closest embeddings:\", np.average(similar_coarse_labels))\n",
    "print(\"fine similarity of closest embeddings:\", np.average(similar_fine_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth: 32\n",
      "most likely coarse classes: [10 16 18 12 13 19  5  9  8  1]\n",
      "related logits: [ 3.15512204  1.56414711  0.98855859  0.88257843  0.71131492]\n",
      "direct prediction: 52\n",
      "prediction from tree: ([10, 52], 52)\n",
      "fine class logits for pred 0: [ 1.09191775 -4.78961182  4.39650345  3.17693973 -4.01157379]\n",
      "fine class logits for pred 1: [-3.77936649 -0.46914208  4.22204351 -0.38641715 -6.27486038]\n",
      "fine class logits for pred 2: [-2.58437538  3.57638478 -2.87277913 -3.68798852 -8.0533905 ]\n",
      "fine class logits for ground truth coarse: [-5.1884141  -0.49775699 -4.13259411 -2.81988502 -0.26474103]\n",
      "accuracy: 0.0102\n",
      "coarse accuracy: 0.0508\n",
      "coarse is right, but fine fails: 0.0436\n",
      "coarse is right, but fine fails also on subset of tree: 0.0396\n",
      "coarse is wrong, fine still right: 0.003\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "#print(imgs[i])\n",
    "#plt.imshow(imgs[i])\n",
    "\n",
    "labels = (y+99) % 100\n",
    "\n",
    "print \"ground truth:\", labels[i]\n",
    "s = res[1][i][0:20].argsort()[-10:][::-1]\n",
    "print \"most likely coarse classes:\", s\n",
    "print \"related logits:\", np.sort(res[1][i][0:20])[-5:][::-1]\n",
    "\n",
    "print \"direct prediction:\", findLabelsFromTreeMultitask(tree, res[1][i])[1]  \n",
    "print \"prediction from tree:\", findLabelsFromTree(tree, res[1][i])  \n",
    "print \"fine class logits for pred 0:\", res[1][i][s[0]*5+20:s[0]*5+25]\n",
    "print \"fine class logits for pred 1:\", res[1][i][s[1]*5+20:s[1]*5+25]\n",
    "print \"fine class logits for pred 2:\", res[1][i][s[2]*5+20:s[2]*5+25]\n",
    "\n",
    "print \"fine class logits for ground truth coarse:\", res[1][i][int(np.floor((y[i]-1)/5)*5+20):int(np.floor((y[i]-1)/5)*5+25)]\n",
    "\n",
    "correct=[]\n",
    "correct_coarse=[]\n",
    "not_correct_but_coarse=[]\n",
    "correct_but_not_coarse=[]\n",
    "subset_wrong=[]\n",
    "s=5000\n",
    "for j in range(s):\n",
    "    tree_label = findLabelsFromTree(tree, res[1][j])\n",
    "    label = findLabelsFromTreeMultitask(tree, res[1][j])\n",
    "    coarse_label = int(np.math.floor((labels[j]) / 5))\n",
    "    \n",
    "    if label[1] == labels[j]:\n",
    "        correct = correct + [j]\n",
    "        if label[0] != coarse_label:\n",
    "            correct_but_not_coarse = correct_but_not_coarse + [j]\n",
    "            \n",
    "    if label[0] == coarse_label:\n",
    "        correct_coarse = correct_coarse + [j]\n",
    "        if tree_label[0][1] != labels[j]:\n",
    "            subset_wrong = subset_wrong + [j]\n",
    "        if label[1] != labels[j]:\n",
    "            not_correct_but_coarse = not_correct_but_coarse + [j]\n",
    "            \n",
    "        \n",
    "print \"accuracy:\", float(len(correct))/s\n",
    "print \"coarse accuracy:\", float(len(correct_coarse))/s\n",
    "print \"coarse is right, but fine fails:\", float(len(not_correct_but_coarse))/s\n",
    "print \"coarse is right, but fine fails also on subset of tree:\", float(len(subset_wrong))/s\n",
    "print \"coarse is wrong, fine still right:\", float(len(correct_but_not_coarse))/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the embedding\n",
    "\n",
    "We now create a $N \\times p$ matrix holding the embeddings, for the N images. For simplycify, we do this by feeding the images one after another through the network (of course we could have also used minibatches). We store this matrix in `EMB` to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n"
     ]
    }
   ],
   "source": [
    "N = imgs.shape[0]\n",
    "N = 2000 #For testing \n",
    "p = res[0].shape[1]\n",
    "\n",
    "EMB = np.zeros((N, p), dtype='float32')\n",
    "for i in range(N): #Of course you could do mini-batches\n",
    "    EMB[i] = sess.run(fetch, feed_dict={feed: imgs[i:i+1,:]})\n",
    "    if (i % 50 == 0 or i < 5):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing out the embedding matrix\n",
    "We now write out the embedding matrix in the proper format needed for the visualizer. If you don't want images or meta data, just comment out the respective parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/stud/plapp/cifarVisualization/model5.ckpt-1'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_DIR = '/usr/stud/plapp/cifarVisualization'\n",
    "\n",
    "# The embedding variable, which needs to be stored\n",
    "# Note this must a Variable not a Tensor!\n",
    "embedding_var = tf.Variable(EMB,  name='Embedding_of_fc4')\n",
    "sess.run(embedding_var.initializer)\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR)\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "\n",
    "# Comment out if you don't have metadata\n",
    "embedding.metadata_path = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "\n",
    "# Comment out if you don't want sprites\n",
    "#embedding.sprite.image_path = os.path.join(LOG_DIR, 'sprite.png')\n",
    "#embedding.sprite.single_image_dim.extend([imgs.shape[1], imgs.shape[1]])\n",
    "\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "saver = tf.train.Saver([embedding_var])\n",
    "saver.save(sess, os.path.join(LOG_DIR, 'model5.ckpt'), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the meta data (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['plane','auto','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "metadata_file = open(os.path.join(LOG_DIR, 'metadata.tsv'), 'w')\n",
    "metadata_file.write('Name\\tClass\\n')\n",
    "for i in range(N):\n",
    "    metadata_file.write('%06d\\t%s\\n' % (i, 'class'+str(y[i])))\n",
    "metadata_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taken from: https://github.com/tensorflow/tensorflow/issues/6322\n",
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    #data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "            + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sprite = images_to_sprite(imgs)\n",
    "scipy.misc.imsave(os.path.join(LOG_DIR, 'sprite.png'), sprite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 139768\r\n",
      "-rw-r--r--  1 oli  wheel   103B Dec 16 18:36 checkpoint\r\n",
      "-rw-r--r--  1 oli  wheel    12K Dec 16 18:36 metadata.tsv\r\n",
      "-rw-r--r--  1 oli  wheel    16M Dec 16 18:36 model2.ckpt-1.data-00000-of-00001\r\n",
      "-rw-r--r--  1 oli  wheel   147B Dec 16 18:36 model2.ckpt-1.index\r\n",
      "-rw-r--r--  1 oli  wheel    31M Dec 16 18:36 model2.ckpt-1.meta\r\n",
      "-rw-r--r--  1 oli  wheel   199B Dec 16 18:36 projector_config.pbtxt\r\n",
      "-rw-r--r--  1 oli  wheel    21M Dec 16 18:36 sprite.png\r\n"
     ]
    }
   ],
   "source": [
    "%ls -lhl /tmp/dumm/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
